{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/wiki'\n",
    "k=0.5\n",
    "col='label'\n",
    "txt='text'\n",
    "df = pd.read_csv(f'{DATA_PATH}/train_original_split.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Number of Classes---\n",
      "2\n",
      "---Vocab Size Pre Stemming---\n",
      "83022\n",
      "---Building Inverse Stemming Lookup---\n",
      "---Vocab Size Post Stemming---\n",
      "55349\n"
     ]
    }
   ],
   "source": [
    "list_of_classes = list(set(df[col]))\n",
    "NUM_OF_CLASSES = len(list_of_classes)\n",
    "print('---Number of Classes---')\n",
    "print(NUM_OF_CLASSES)\n",
    "all_sents = list(df['text'])\n",
    "all_tokenized_sents = [word_tokenize(s) for s in all_sents]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentences_stopped = [[x for x in y if not x.lower() in stop_words]for y in all_tokenized_sents]\n",
    "\n",
    "vocab_pre_stem = list(set([word for s in sentences_stopped for word in s]))\n",
    "print('---Vocab Size Pre Stemming---')\n",
    "print(len(vocab_pre_stem))\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "print('---Building Inverse Stemming Lookup---')\n",
    "inverse_stem_lookup = defaultdict(set)\n",
    "for v in vocab_pre_stem:\n",
    "    inverse_stem_lookup[ps.stem(v)].add(v)\n",
    "\n",
    "all_stemmed_sents = [[ps.stem(w) for w in s] for s in all_tokenized_sents]\n",
    "vocab_post_stem = list(set([word for s in all_stemmed_sents for word in s]))\n",
    "\n",
    "print('---Vocab Size Post Stemming---')\n",
    "VOCAB_SIZE = len(vocab_post_stem)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neurographi',\n",
       " '1942',\n",
       " 'id=ncu8snx2cgec',\n",
       " 'outweight',\n",
       " 'coddl',\n",
       " '4/22',\n",
       " 'x',\n",
       " 'dvdm',\n",
       " 'lphant',\n",
       " 'artistri']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_post_stem[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[txt].str.contains('neurographi')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens_full</th>\n",
       "      <th>tokens_clean</th>\n",
       "      <th>tokens_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:If I may butt in I've spent the last 1/4 hour...</td>\n",
       "      <td>0</td>\n",
       "      <td>[:, If, I, may, butt, in, I, 've, spent, the, ...</td>\n",
       "      <td>[if, i, may, butt, i, spent, last, hour, follo...</td>\n",
       "      <td>[if, i, may, butt, i, spent, last, hour, follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On my you will find the apology that I owe you...</td>\n",
       "      <td>0</td>\n",
       "      <td>[On, my, you, will, find, the, apology, that, ...</td>\n",
       "      <td>[on, find, apology, i, owe, shuffles, feet, lo...</td>\n",
       "      <td>[on, find, apolog, i, owe, shuffl, feet, look,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, that's Twin cities from which this articl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Yep, ,, that, 's, Twin, cities, from, which, ...</td>\n",
       "      <td>[yep, twin, cities, article, originated]</td>\n",
       "      <td>[yep, twin, citi, articl, origin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>See? I was right! ;-)</td>\n",
       "      <td>0</td>\n",
       "      <td>[See, ?, I, was, right, !, ;, -, )]</td>\n",
       "      <td>[see, i, right]</td>\n",
       "      <td>[see, i, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>` Thanks for fixing the spelling error in ``pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[`, Thanks, for, fixing, the, spelling, error,...</td>\n",
       "      <td>[thanks, fixing, spelling, error, propaganda, ...</td>\n",
       "      <td>[thank, fix, spell, error, propaganda, i, ca, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23134</th>\n",
       "      <td>` kys {| style=``background-color: #fdffe7; bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[`, kys, {, |, style=, ``, background-color, :...</td>\n",
       "      <td>[kys, fdffe7, border, 1px, solid, fceb92, 2, m...</td>\n",
       "      <td>[ky, fdffe7, border, 1px, solid, fceb92, 2, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23135</th>\n",
       "      <td>Yeah, I realized I created a duplicate ID. Sor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Yeah, ,, I, realized, I, created, a, duplicat...</td>\n",
       "      <td>[yeah, i, realized, i, created, duplicate, id,...</td>\n",
       "      <td>[yeah, i, realiz, i, creat, duplic, id, sorri,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23136</th>\n",
       "      <td>` :::Yeah and in the earlier sentence I'd rewo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[`, :, :, :, Yeah, and, in, the, earlier, sent...</td>\n",
       "      <td>[yeah, earlier, sentence, i, reword, fever, pi...</td>\n",
       "      <td>[yeah, earlier, sentenc, i, reword, fever, pitch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23137</th>\n",
       "      <td>Why oh why... You removed the trolls ANI secti...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Why, oh, why, ..., You, removed, the, trolls,...</td>\n",
       "      <td>[why, oh, you, removed, trolls, ani, section, ...</td>\n",
       "      <td>[whi, oh, you, remov, troll, ani, section, drm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23138</th>\n",
       "      <td>The Institute for Historical Review is a peer-...</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, Institute, for, Historical, Review, is, ...</td>\n",
       "      <td>[the, institute, historical, review, journal, ...</td>\n",
       "      <td>[the, institut, histor, review, journal, well,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23139 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      :If I may butt in I've spent the last 1/4 hour...      0   \n",
       "1      On my you will find the apology that I owe you...      0   \n",
       "2      Yep, that's Twin cities from which this articl...      0   \n",
       "3                                  See? I was right! ;-)      0   \n",
       "4      ` Thanks for fixing the spelling error in ``pr...      0   \n",
       "...                                                  ...    ...   \n",
       "23134  ` kys {| style=``background-color: #fdffe7; bo...      0   \n",
       "23135  Yeah, I realized I created a duplicate ID. Sor...      0   \n",
       "23136  ` :::Yeah and in the earlier sentence I'd rewo...      0   \n",
       "23137  Why oh why... You removed the trolls ANI secti...      0   \n",
       "23138  The Institute for Historical Review is a peer-...      0   \n",
       "\n",
       "                                             tokens_full  \\\n",
       "0      [:, If, I, may, butt, in, I, 've, spent, the, ...   \n",
       "1      [On, my, you, will, find, the, apology, that, ...   \n",
       "2      [Yep, ,, that, 's, Twin, cities, from, which, ...   \n",
       "3                    [See, ?, I, was, right, !, ;, -, )]   \n",
       "4      [`, Thanks, for, fixing, the, spelling, error,...   \n",
       "...                                                  ...   \n",
       "23134  [`, kys, {, |, style=, ``, background-color, :...   \n",
       "23135  [Yeah, ,, I, realized, I, created, a, duplicat...   \n",
       "23136  [`, :, :, :, Yeah, and, in, the, earlier, sent...   \n",
       "23137  [Why, oh, why, ..., You, removed, the, trolls,...   \n",
       "23138  [The, Institute, for, Historical, Review, is, ...   \n",
       "\n",
       "                                            tokens_clean  \\\n",
       "0      [if, i, may, butt, i, spent, last, hour, follo...   \n",
       "1      [on, find, apology, i, owe, shuffles, feet, lo...   \n",
       "2               [yep, twin, cities, article, originated]   \n",
       "3                                        [see, i, right]   \n",
       "4      [thanks, fixing, spelling, error, propaganda, ...   \n",
       "...                                                  ...   \n",
       "23134  [kys, fdffe7, border, 1px, solid, fceb92, 2, m...   \n",
       "23135  [yeah, i, realized, i, created, duplicate, id,...   \n",
       "23136  [yeah, earlier, sentence, i, reword, fever, pi...   \n",
       "23137  [why, oh, you, removed, trolls, ani, section, ...   \n",
       "23138  [the, institute, historical, review, journal, ...   \n",
       "\n",
       "                                             tokens_stem  \n",
       "0      [if, i, may, butt, i, spent, last, hour, follo...  \n",
       "1      [on, find, apolog, i, owe, shuffl, feet, look,...  \n",
       "2                      [yep, twin, citi, articl, origin]  \n",
       "3                                        [see, i, right]  \n",
       "4      [thank, fix, spell, error, propaganda, i, ca, ...  \n",
       "...                                                  ...  \n",
       "23134  [ky, fdffe7, border, 1px, solid, fceb92, 2, mi...  \n",
       "23135  [yeah, i, realiz, i, creat, duplic, id, sorri,...  \n",
       "23136  [yeah, earlier, sentenc, i, reword, fever, pitch]  \n",
       "23137  [whi, oh, you, remov, troll, ani, section, drm...  \n",
       "23138  [the, institut, histor, review, journal, well,...  \n",
       "\n",
       "[23139 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens_full'] = df.apply(lambda x: word_tokenize(x[txt]), axis=1)\n",
    "df['tokens_clean'] = df.apply(lambda x: [w.lower() for w in x['tokens_full'] if w not in stop_words and w.isalnum()], axis=1)\n",
    "df['tokens_stem'] = df.apply(lambda x: [ps.stem(w) for w in x['tokens_clean']], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [x for y in df['tokens_stem'] for x in y]\n",
    "count = Counter(tokens)\n",
    "count_class = Counter(df['label'])\n",
    "\n",
    "VOCAB_SIZE = len(count.keys())\n",
    "NUM_OF_TOKENS = sum(count.values())\n",
    "NUM_OF_CLASSES = len(count_class.keys())\n",
    "NUM_OF_RECORDS = sum(count_class.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40553"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for k, v in count.items():\n",
    "    if v == 1:\n",
    "        c +=1\n",
    "        \n",
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23139"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count_class.values())\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = np.zeros((VOCAB_SIZE, NUM_OF_CLASSES))\n",
    "prior = np.zeros((NUM_OF_CLASSES,1))\n",
    "norm = np.zeros((VOCAB_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(count.keys())\n",
    "classes = list(count_class.keys())\n",
    "for k, v in count_class.items():\n",
    "    sub_df = df[df['label']==k]\n",
    "    sub_tokens = [x for y in sub_df['tokens_stem'] for x in y]\n",
    "    prior[classes.index(k), 0] = v / len(df)\n",
    "    sub_token_count = Counter(sub_tokens)\n",
    "    for s_token, s_count in sub_token_count.items():\n",
    "        likelihood[vocab.index(s_token), classes.index(k)] = s_count / sum(sub_token_count.values())\n",
    "        \n",
    "for k, v in count.items():\n",
    "    norm[vocab.index(k), 0] = v / NUM_OF_TOKENS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90466626, 0.09664234],\n",
       "       [0.8807418 , 0.11923531],\n",
       "       [0.98000006, 0.02550114],\n",
       "       ...,\n",
       "       [1.00700407, 0.        ],\n",
       "       [0.        , 0.95096063],\n",
       "       [1.00700407, 0.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood * np.repeat(prior,VOCAB_SIZE,axis=1).T / np.repeat(norm, NUM_OF_CLASSES, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915554"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_TOKENS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
